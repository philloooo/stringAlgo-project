def OutputRelations(abstractFileName,geneFileName,posFileName,negFileName,neutralFileName,negationsFileName):
    
                                                
                                                
                                                
                                                
    import nltk
    import copy
    import re
    from nltk.stem.lancaster import LancasterStemmer
    from nltk.stem import RegexpStemmer
    #sentenceinfo contains info on the sentence, the num of genes in the sentence,
    #the relation,
    sentencedb = dict()
    countsentences=0
    def isGene(x,t):
        if len(t)>1:
            
            if t.index(x) ==0:
                if t[t.index(x)+1] in [">","<","=","score"]:
                    return False
            elif t.index(x) ==len(t)-1:
                if t[t.index(x)-1] in [">","<","=","score"]:
                    return False
            elif(t[t.index(x)+1] in [">","<","=","score"])or (
                t[t.index(x)-1] in [">","<","=","score"]):
                return False
            else:
                return True
            return True
        else:
            return False

    def countgenes(s,geneset):
        s=nltk.word_tokenize(s)
        numgenes=0
        existingGenes = []
        for i in s:
            if i in geneset and isGene(i,s) and i not in existingGenes:
                numgenes+=1
                existingGenes.append(i)  
                
        
        return numgenes

    def countWords(gene1,gene2,token):
        #counts the words between gene 1 and gene2
        count = 0
        for i in xrange(token.index(gene1)+1,token.index(gene2) -1):
            count+=1
        return count
            
            

    #blah = line.split("\t")
    abstracts = open(abstractFileName,"r")
    
    def readf(filename):
        file = open(filename,"r")
        a = file.read()
        a = a = a.split("\n")
        file.close()
        return a
    storage = dict()
    #x= open(r"C:\Python27\finalGeneSymbols.txt","r")
    #x= open(geneFileName,"r")
    #a=x.read()
    #a = a.split("\n")
    seta= set(readf(geneFileName))
    #print seta
    

        
        
    for x in abstracts:
        #print x
        x =x.split("\t")
        #sentences=splitParagraphIntoSentences(x[-1])
        
        #sentencelist=(x[-1]).split(". ")
        sentencelist =re.split("\. (?=[A-Z])",x[-1])
        sentencelistcopy=copy.deepcopy(sentencelist)
        l = len(sentencelist)
        for i in xrange(l):
            
            if countgenes(sentencelistcopy[i],seta)<2:
                sentencelist.remove(sentencelistcopy[i])
                
        #print sentences
        #print type(x[-1])
        storage[x[0]] = sentencelist
        #print x[0]
    #print abstracts
    abstracts.close()
        


    
    num_genes=0
    bw=0
    gene_names = seta
    
    
    posSet= set(readf(posFileName))
    
    negSet= set(readf(negFileName))
    
    neutralSet= set(readf(neutralFileName))
    
    negationSet= set(readf(negationsFileName))

    
    
    st = RegexpStemmer('ing$|s$|e$|ed$|es$', min=4)
    def findsuf(string,x):
        a = ""
        for i in xrange(x):
            a+=string[len(string)-1-(x-i-1)]
            
        return a
    finalOutput=[]

            
        
    for id in storage:
        for sentence in storage[id]:
            
            rlist = [0,0,0]
            #sentence = storage[id]
            relation = "none"
            
            tokens = nltk.word_tokenize(sentence)
            tokenscopy = copy.deepcopy(tokens)
            tagged = nltk.pos_tag(tokens)
            

            for x in tagged:
                
                if x[1] in ['VBP','VBN','VBZ','VBG','VB'] : 
                    tokenscopy[tagged.index(x)] = st.stem(x[0])
            store=0
            genes = []
            #print tokens,tokenscopy
            relation = "none"
            direction = 0
            for x in tokens:
                
                if x in gene_names:
                    genes.append(x)
                    num_genes+=1
                    #store = tokens.index(x)
            
            in1 = tokens.index(genes[0])
            in2 = tokens.index(genes[1])
            indexx=0
            neg=1
            if countWords(genes[0],genes[1],tokenscopy)<=6:
                
                
                    
                    
                for i in xrange(in1 +1,in2):
                    
                    
                    if tokenscopy[i] in posSet:
                        relation = 1
                        
                        
                        
                    elif tokenscopy[i] in negSet:
                        relation = -1
                    #elif tokenscopy[i] in neutralSet:
                        #relation = 0
                    
                    if (tokenscopy[i] in negSet or tokenscopy[i] in
                        posSet):
                        for y in xrange(in1+1,tokenscopy.index(tokenscopy[i])):
                            if tokenscopy[y]=="not":
                                relation =2
                                #2 means neutral
                        if  findsuf(tokens[i],2)=="ed":
                            direction =1
                            
                        else:
                            direction =0
                        
                        
                if direction ==0:
                    rlist = [genes[0],genes[1],relation]
                    #print genes[0],relation,genes[1]
                elif direction == 1 :
                    rlist = [genes[1],genes[0],relation]
                    #print genes[1], relation, genes[0]
                if relation!="none":
                    #the above condition is so that it does not output sentences for which no relation
                    #has been found. This makes analysis easier. Must change this during final program.
                    sentencedb[countsentences]=sentence
                    #use this to have the sentences represented by a number
                    finalOutput.append([id,sentence,rlist])
                    #use this to have the actual sentences in the output
                    #finalOutput.append([id,sentence,rlist])
                    
                    countsentences+=1
          
             
    print finalOutput

#use below info to run
##abstractFileName="C:/Python27/abstractsNew.txt"
##geneFileName="C:/Python27/finalGeneSymbols.txt"
##posFileName="C:/Python27/worddictionaries/posWords.txt"
##negFileName="C:/Python27/worddictionaries/negWords.txt"
##neutralFileName= "C:/Python27/worddictionaries/neutralWords.txt"
##negationsFileName="C:/Python27/worddictionaries/negations.txt"
##OutputRelations(abstractFileName,geneFileName,posFileName,negFileName,neutralFileName,negationsFileName)
